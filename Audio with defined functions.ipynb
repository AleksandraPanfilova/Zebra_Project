{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995fe6df",
   "metadata": {},
   "source": [
    "# Audio Bulk Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f02028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92bb811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels_to_excel():\n",
    "    \"\"\"Returns dataframe of spreadsheet with labels\"\"\"\n",
    "    df = pd.read_excel('Zebras.Assumption.data_Bing_413 .xlsx', sheet_name=2)\n",
    "    labels = []\n",
    "    for filename in df['file']:\n",
    "        label = re.search(\"squeal|whinnie|softsnort|snort\", filename)\n",
    "        if label:\n",
    "            label = label.group(0)\n",
    "            labels.append(label)\n",
    "    df['label'] = labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997dc561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_labels_to_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad43fa29",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4036371784.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [4]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for i in tqdm(range(len(df['file'])):\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def gen_audio_array(folder_path):\n",
    "    \"\"\" Loads and pads audio files to be of uniform shape\"\"\"\n",
    "    audio_size = 0\n",
    "    for i in range(len(df['file'])):\n",
    "        audio, _ = librosa.load(folder_path+df['file'][i])\n",
    "        if len(audio)>audio_size:\n",
    "            audio_size = len(audio)\n",
    "            index_longest = i\n",
    "    audio_files = np.zeros((413,audio_size))\n",
    "\n",
    "    for i in tqdm(range(len(df['file'])):\n",
    "        audio, _ = librosa.load(folder_path+df['file'][i])\n",
    "        padding_amount = int((audio_size - len(audio))/2)\n",
    "        audio_padded = np.pad(audio,padding_amount)\n",
    "        if (len(audio_padded) % 2) == 0:\n",
    "            audio_padded = np.append(audio_padded,[0])\n",
    "        audio_files[i,:] = audio_padded\n",
    "    return audio_files, audio_size, index_longest\n",
    "    \n",
    "audio_files, audio_size, index_longest = gen_audio_array('zebra audio sample_Bing_413/all/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audio_files[1,:])\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ebe742",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4579ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_labels = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a097af",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05151934",
   "metadata": {},
   "source": [
    "# Claculate BPMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ccb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "BPMs = np.zeros((len(audio_files[:,1])))\n",
    "for i in range(413):\n",
    "    BPMs[i] = librosa.beat.tempo(audio_files[i,:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f51938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BPM'] = BPMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd82213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653788f",
   "metadata": {},
   "source": [
    "# Sample Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f193bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer(audio,max_frac_shift):\n",
    "    shift_max = int(audio.shape[0]*max_frac_shift)\n",
    "    buffer_array = np.zeros(shift_max)\n",
    "    audio_buff = np.append(audio,buffer_array, axis=0)\n",
    "    audio_buff = np.append(buffer_array,audio_buff, axis=0)\n",
    "    return audio_buff\n",
    "\n",
    "def shifter(audio,max_frac_shift):\n",
    "    shift_max = int(audio.shape[0]*max_frac_shift)\n",
    "    audio_shift = np.roll(audio, random.randint(-shift_max,shift_max))\n",
    "    return audio_shift\n",
    "\n",
    "def louder(audio, max_frac_louder):\n",
    "    max_change = int(max_frac_louder*100)\n",
    "    random_change = random.randint(100-max_change,max_change)/100\n",
    "    return audio*random_change\n",
    "\n",
    "def plot_mel(audio):\n",
    "    file1_mel = librosa.amplitude_to_db(librosa.feature.melspectrogram(y=audio))\n",
    "    plt.imshow(file1_mel,aspect='auto')\n",
    "    plt.colorbar(label='dB')\n",
    "    #plt.xlabel('Frequency Bin')\n",
    "    #plt.ylabel('Frame')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6bacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_audio(audio_files):\n",
    "    time_shift = 0.1 # fractional ranges\n",
    "    vol_shift = 1.1 \n",
    "    n_samples = audio_files.shape[0]\n",
    "    width_buffer = int(audio_files.shape[1]*(1+time_shift*2))\n",
    "    buffer_shape = (n_samples,width_buffer)\n",
    "    \n",
    "\n",
    "    audio_files_norm = np.zeros(audio_files.shape) # assume beyond this point (unlabelled)\n",
    "    audio_files_buff = np.zeros(buffer_shape)\n",
    "    audio_files_shift1 = np.zeros(buffer_shape)\n",
    "    audio_files_shift2 = np.zeros(buffer_shape)\n",
    "    audio_files_loud = np.zeros(buffer_shape) # random intensity shift (whole file)\n",
    "    audio_files_noisy = np.zeros(audio_files.shape)\n",
    "    audio_files_noisy_buff = np.zeros(buffer_shape)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        audio_files_norm[i,:] = librosa.util.normalize(audio_files[i,:]) \n",
    "        audio_files_buff[i,:]  = buffer(audio_files_norm[i,:],time_shift)\n",
    "        audio_files_shift1[i,:] = shifter(audio_files_buff[i,:],time_shift)\n",
    "        audio_files_shift2[i,:] = shifter(audio_files_buff[i,:],time_shift)\n",
    "        audio_files_loud[i,:] = louder(audio_files_buff[i,:],vol_shift)\n",
    "        \n",
    "    noise = np.random.normal(0,0.01,39923)\n",
    "\n",
    "    ## For noise in buffer:\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        for j in range(39923):\n",
    "            if audio_files_norm[i,j] != 0:\n",
    "                audio_files_noisy[i,j] =  audio_files_norm[i,j] + noise[j]\n",
    "            else:\n",
    "                audio_files_noisy[i,j] =  audio_files_norm[i,j]\n",
    "        audio_files_noisy_buff[i,:] = buffer(audio_files_noisy[i,:],time_shift)   \n",
    "        \n",
    "    data_for_NN = np.zeros((5,n_samples,47907))\n",
    "    data_for_NN[0,:,:] = audio_files_buff # All normalised 1st\n",
    "    data_for_NN[1,:,:] = audio_files_shift1\n",
    "    data_for_NN[2,:,:] = audio_files_shift2\n",
    "    data_for_NN[3,:,:] = audio_files_noisy_buff\n",
    "    data_for_NN[4,:,:] = audio_files_loud\n",
    "        \n",
    "    return data_for_NN\n",
    "\n",
    "augmented_samples = augment_audio(audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e784a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(audio_files[index_longest,:],label='raw')\n",
    "def plot_sample(sample_index):\n",
    "    plt.plot(augmented_samples[0,sample_index,:],label='buff')\n",
    "    plt.plot(augmented_samples[1,sample_index,:],label='shift1')\n",
    "    plt.plot(augmented_samples[2,sample_index,:],label='shift2')\n",
    "    plt.plot(augmented_samples[3,sample_index,:],label='noisy')\n",
    "    plt.plot(augmented_samples[4,sample_index,:],label='loud')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43156b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 1\n",
    "plot_sample(sample_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57589fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(augmented_samples[3,sample_index,:], label='noisy')\n",
    "plt.plot(augmented_samples[0,sample_index,:]-augmented_samples[3,sample_index,:], label='norm - noisy')\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef88e6c9",
   "metadata": {},
   "source": [
    "## Sample Rate Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95237c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsr_loader(folder_path):\n",
    "    hsr=22050*2\n",
    "    audio_size_hsr = int(audio_size*(hsr/22050))\n",
    "    audio_files_hsr = np.zeros((413,audio_size_hsr))\n",
    "    for i in range(len(df['file'])):\n",
    "        audio, _ = librosa.load((folder_path+df['file'][i]), sr=hsr)\n",
    "        padding_amount = int((audio_size_hsr - len(audio))/2)\n",
    "        audio_padded = np.pad(audio,padding_amount)\n",
    "        if (len(audio_padded) % 2) != 0:\n",
    "            audio_padded = np.append(audio_padded,[0])\n",
    "        audio_files_hsr[i,:] = audio_padded\n",
    "    return audio_files_hsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad1be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsr_loader(folder_path):\n",
    "    lsr=22050/2\n",
    "    audio_size_lsr = int(audio_size*(lsr/22050))+1\n",
    "    audio_files_lsr = np.zeros((413,audio_size_lsr))\n",
    "    for i in range(len(df['file'])):\n",
    "        audio, _ = librosa.load((folder_path+df['file'][i]), sr=lsr)\n",
    "        padding_amount = int((audio_size_lsr - len(audio))/2)\n",
    "        audio_padded = np.pad(audio,padding_amount)\n",
    "        if (len(audio_padded) % 2) != 0:\n",
    "            audio_padded = np.append(audio_padded,[0])\n",
    "        audio_files_lsr[i,:] = audio_padded\n",
    "    return audio_files_lsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21226835",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files_hsr = hsr_loader('zebra audio sample_Bing_413/all/')\n",
    "audio_files_lsr = lsr_loader('zebra audio sample_Bing_413/all/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6629d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audio_files_hsr[0,:],label='hsr')\n",
    "plt.plot(audio_files[0,:],label='ssr')\n",
    "plt.plot(audio_files_lsr[0,:],label='lsr')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6043e7",
   "metadata": {},
   "source": [
    "# Spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stft = np.abs(librosa.stft(audio_files[100]))\n",
    "audio_mel = librosa.feature.melspectrogram(y=audio_files[100])\n",
    "print(audio_stft.shape)\n",
    "print(audio_mel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1962b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stft(augmented_samples):\n",
    "    n_augments = augmented_samples.shape[0]\n",
    "    n_samples = augmented_samples.shape[1]\n",
    "    test_shape = np.abs(librosa.stft(y=augmented_samples[0,0,:])).shape\n",
    "    sftfs_0 = test_shape[0]\n",
    "    sftfs_1 = test_shape[1]\n",
    "    audio_stfts = np.zeros((n_augments,n_samples,sftfs_0,sftfs_1))\n",
    "    for i in range(n_augments):\n",
    "        for j in range(n_samples):\n",
    "            audio_stfts[i,j,:,:] = np.abs(librosa.stft(y=augmented_samples[i,j,:]))\n",
    "    return audio_stfts\n",
    "\n",
    "def calc_melstft(augmented_samples):\n",
    "    n_augments = augmented_samples.shape[0]\n",
    "    n_samples = augmented_samples.shape[1]\n",
    "    test_shape = np.abs(librosa.feature.melspectrogram(y=augmented_samples[0,0,:])).shape\n",
    "    sftfs_0 = test_shape[0]\n",
    "    sftfs_1 = test_shape[1]\n",
    "    audio_mel = np.zeros((n_augments,n_samples,sftfs_0,sftfs_1))\n",
    "    for i in range(n_augments):\n",
    "        for j in range(n_samples):\n",
    "            audio_mel[i,j,:,:] = np.abs(librosa.feature.melspectrogram(y=augmented_samples[i,j,:]))\n",
    "    return audio_mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408fa1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stfts = calc_stft(augmented_samples)\n",
    "audio_mel = calc_melstft(augmented_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627499ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(librosa.amplitude_to_db(audio_stfts[0,100,:,:]),aspect='auto', origin='lower')\n",
    "plt.title('STFT Spectogram')\n",
    "plt.colorbar(label='dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55fadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(librosa.amplitude_to_db(audio_mel[0,100,:,:]),aspect='auto',origin='lower')\n",
    "plt.title(\"Mel Spectogram\")\n",
    "plt.colorbar(label='dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c29451",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(librosa.amplitude_to_db(audio_mel[3,100,:,:]),aspect='auto', origin='lower')\n",
    "plt.title(\"Mel Spectogram + 1% Noise\")\n",
    "plt.colorbar(label='dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.specgram(audio_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5b890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
